{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Creating the inference container\n",
    "# Backup\n",
    "\n",
    "# %%writefile Dockerfile\n",
    "# FROM python:3.7-buster\n",
    "\n",
    "# # Set a docker label to advertise multi-model support on the container\n",
    "# LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# # Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "# LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "# RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "# RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "# RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "# COPY dist/sagemaker-custom-0.1.0.tar.gz /sagemaker-custom-0.1.0.tar.gz\n",
    "# RUN pip --no-cache install /sagemaker-custom-0.1.0.tar.gz && \\\n",
    "#     rm /sagemaker-custom-0.1.0.tar.gz\n",
    "\n",
    "# ENV PYTHONUNBUFFERED=TRUE\n",
    "# ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "# ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "# #####################\n",
    "# # Required ENV vars #\n",
    "# #####################\n",
    "# # Set SageMaker training environment variables\n",
    "# ENV SM_INPUT /opt/ml/input\n",
    "# ENV SM_INPUT_TRAINING_CONFIG_FILE $SM_INPUT/config/hyperparameters.json\n",
    "# ENV SM_INPUT_DATA_CONFIG_FILE $SM_INPUT/config/inputdataconfig.json\n",
    "# ENV SM_CHECKPOINT_CONFIG_FILE $SM_INPUT/config/checkpointconfig.json\n",
    "\n",
    "# # Set SageMaker serving environment variables\n",
    "# ENV SM_MODEL_DIR /opt/ml/model\n",
    "\n",
    "# ENV CODE_DIR /opt/ml/code\n",
    "# # COPY main.py $CODE_DIR/main.py\n",
    "# COPY src/my_training.py $CODE_DIR/my_training.py\n",
    "# COPY src/my_serving.py $CODE_DIR/my_serving.py\n",
    "\n",
    "# COPY src/handler_service.py $CODE_DIR/handler_service.py\n",
    "# COPY src/inference_handler.py $CODE_DIR/inference_handler.py\n",
    "\n",
    "# ENV SAGEMAKER_TRAINING_MODULE my_training:main\n",
    "# ENV SAGEMAKER_SERVING_MODULE my_serving:main\n",
    "\n",
    "# # ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Creating our Python Package with the SageMaker Inference Toolkit\n",
    "\n",
    "# !pip install sagemaker-training sagemaker-inference multi-model-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/ec2-user/SageMaker/sagemaker_custom/1_custom_inference/package\n",
      "Requirement already satisfied: sagemaker-inference==1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from custom-lightgbm-inference==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: multi-model-server==1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from custom-lightgbm-inference==0.1.0) (1.1.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (5.7.0)\n",
      "Requirement already satisfied: typing in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: retrying==1.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.18.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (0.18.2)\n",
      "Requirement already satisfied: model-archiver in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (1.0.3)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (7.0.0)\n",
      "Requirement already satisfied: enum-compat in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from model-archiver->multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (0.0.3)\n",
      "Installing collected packages: custom-lightgbm-inference\n",
      "  Attempting uninstall: custom-lightgbm-inference\n",
      "    Found existing installation: custom-lightgbm-inference 0.1.0\n",
      "    Uninstalling custom-lightgbm-inference-0.1.0:\n",
      "      Successfully uninstalled custom-lightgbm-inference-0.1.0\n",
      "  Running setup.py develop for custom-lightgbm-inference\n",
      "Successfully installed custom-lightgbm-inference\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd package && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing src/custom_lightgbm_inference.egg-info/PKG-INFO\n",
      "writing dependency_links to src/custom_lightgbm_inference.egg-info/dependency_links.txt\n",
      "writing entry points to src/custom_lightgbm_inference.egg-info/entry_points.txt\n",
      "writing requirements to src/custom_lightgbm_inference.egg-info/requires.txt\n",
      "writing top-level names to src/custom_lightgbm_inference.egg-info/top_level.txt\n",
      "reading manifest file 'src/custom_lightgbm_inference.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/custom_lightgbm_inference.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating custom_lightgbm_inference-0.1.0\n",
      "creating custom_lightgbm_inference-0.1.0/src\n",
      "creating custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "creating custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying files to custom_lightgbm_inference-0.1.0...\n",
      "copying setup.py -> custom_lightgbm_inference-0.1.0\n",
      "copying src/custom_lightgbm_inference/__init__.py -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "copying src/custom_lightgbm_inference/handler.py -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "copying src/custom_lightgbm_inference/my_serving.py -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "copying src/custom_lightgbm_inference.egg-info/PKG-INFO -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/SOURCES.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/dependency_links.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/entry_points.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/requires.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/top_level.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "Writing custom_lightgbm_inference-0.1.0/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'custom_lightgbm_inference-0.1.0' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!cd package/ && python setup.py sdist && cp dist/custom_lightgbm_inference-0.1.0.tar.gz ../docker/code/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running handler service: custom_lightgbm_inference.handler\n",
      "ERROR - Given model-path /opt/ml/model is not a valid directory. Point to a valid model-path directory.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/bin/serve\", line 11, in <module>\n",
      "    load_entry_point('custom-lightgbm-inference', 'console_scripts', 'serve')()\n",
      "  File \"/home/ec2-user/SageMaker/sagemaker_custom/1_custom_inference/package/src/custom_lightgbm_inference/my_serving.py\", line 10, in main\n",
      "    model_server.start_model_server(handler_service=HANDLER_SERVICE)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker_inference/model_server.py\", line 75, in start_model_server\n",
      "    _adapt_to_mms_format(handler_service)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker_inference/model_server.py\", line 122, in _adapt_to_mms_format\n",
      "    subprocess.check_call(model_archiver_cmd)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/subprocess.py\", line 311, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['model-archiver', '--model-name', 'model', '--handler', 'custom_lightgbm_inference.handler', '--model-path', '/opt/ml/model', '--export-path', '/home/ec2-user/SageMaker/sagemaker_custom/1_custom_inference/.sagemaker/mms/models', '--archive-format', 'no-archive']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our Container image.  \n",
    "With this file, CodeBuild will run the \"docker build\" command, using the assets we created above, and deploy the image to the Registry.  \n",
    "As you can see, each command is a bash command that will be executed from inside a Linux Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - Local Test: Let's build the image locally and do some tests\n",
    "### 2.1 Building the image locally, first\n",
    "Each SageMaker Jupyter Notebook already has a **docker** envorinment pre-installed. So we can play with Docker containers just using the same environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and pushing to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   7.68kB\n",
      "Step 1/13 : FROM sagemaker-training-containers/framework-container:latest\n",
      " ---> 6e6a47cf0f36\n",
      "Step 2/13 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> a8cb49fa3ec4\n",
      "Step 3/13 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 7096781dc9d8\n",
      "Step 4/13 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 30b0cfbde1dc\n",
      "Step 5/13 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 65862c7be643\n",
      "Step 6/13 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      " ---> Using cache\n",
      " ---> 3c6656952914\n",
      "Step 7/13 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 8c6ac00dd42a\n",
      "Step 8/13 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      " ---> Running in 076974884a35\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Hit:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu xenial InRelease\n",
      "Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [1160 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [635 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [6680 B]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [1520 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [1036 kB]\n",
      "Fetched 4682 kB in 1s (4114 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java default-jdk-headless default-jre default-jre-headless\n",
      "  java-common libasound2 libasound2-data libasyncns0 libflac8 libgif7\n",
      "  liblcms2-2 libnspr4 libnss3 libnss3-nssdb libpcsclite1 libpulse0 libsndfile1\n",
      "  libxtst6 openjdk-8-jdk openjdk-8-jdk-headless openjdk-8-jre\n",
      "  openjdk-8-jre-headless\n",
      "Suggested packages:\n",
      "  default-java-plugin libasound2-plugins alsa-utils liblcms2-utils pcscd\n",
      "  pulseaudio openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin\n",
      "  libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
      "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
      "Recommended packages:\n",
      "  fonts-dejavu-extra\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java default-jdk default-jdk-headless default-jre\n",
      "  default-jre-headless java-common libasound2 libasound2-data libasyncns0\n",
      "  libflac8 libgif7 liblcms2-2 libnspr4 libnss3 libnss3-nssdb libpcsclite1\n",
      "  libpulse0 libsndfile1 libxtst6 openjdk-8-jdk openjdk-8-jdk-headless\n",
      "  openjdk-8-jre openjdk-8-jre-headless\n",
      "0 upgraded, 23 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 39.5 MB of archives.\n",
      "After this operation, 150 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libasyncns0 amd64 0.8-5build1 [12.3 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxtst6 amd64 2:1.2.2-1 [14.1 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 java-common all 0.56ubuntu2 [7742 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 liblcms2-2 amd64 2.6-3ubuntu2.1 [136 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libnspr4 amd64 2:4.13.1-0ubuntu0.16.04.1 [112 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libnss3-nssdb all 2:3.28.4-0ubuntu0.16.04.13 [10.6 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libnss3 amd64 2:3.28.4-0ubuntu0.16.04.13 [1231 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpcsclite1 amd64 1.8.14-1ubuntu1.16.04.1 [21.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jre-headless amd64 8u265-b01-0ubuntu2~16.04 [27.2 MB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jre-headless amd64 2:1.8-56ubuntu2 [4380 B]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 ca-certificates-java all 20160321ubuntu1 [12.5 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial/main amd64 libasound2-data all 1.1.0-0ubuntu1 [29.4 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial/main amd64 libasound2 amd64 1.1.0-0ubuntu1 [350 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgif7 amd64 5.1.4-0.3~16.04.1 [30.5 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial/main amd64 libflac8 amd64 1.3.1-4 [210 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libsndfile1 amd64 1.0.25-10ubuntu0.16.04.2 [139 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpulse0 amd64 1:8.0-0ubuntu3.12 [253 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jre amd64 8u265-b01-0ubuntu2~16.04 [69.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jre amd64 2:1.8-56ubuntu2 [980 B]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jdk-headless amd64 8u265-b01-0ubuntu2~16.04 [8213 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jdk-headless amd64 2:1.8-56ubuntu2 [986 B]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jdk amd64 8u265-b01-0ubuntu2~16.04 [1453 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jdk amd64 2:1.8-56ubuntu2 [968 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 39.5 MB in 1s (22.4 MB/s)\n",
      "Selecting previously unselected package libasyncns0:amd64.\n",
      "(Reading database ... 23053 files and directories currently installed.)\n",
      "Preparing to unpack .../libasyncns0_0.8-5build1_amd64.deb ...\n",
      "Unpacking libasyncns0:amd64 (0.8-5build1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../libxtst6_2%3a1.2.2-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.2-1) ...\n",
      "Selecting previously unselected package java-common.\n",
      "Preparing to unpack .../java-common_0.56ubuntu2_all.deb ...\n",
      "Unpacking java-common (0.56ubuntu2) ...\n",
      "Selecting previously unselected package liblcms2-2:amd64.\n",
      "Preparing to unpack .../liblcms2-2_2.6-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking liblcms2-2:amd64 (2.6-3ubuntu2.1) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../libnspr4_2%3a4.13.1-0ubuntu0.16.04.1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.13.1-0ubuntu0.16.04.1) ...\n",
      "Selecting previously unselected package libnss3-nssdb.\n",
      "Preparing to unpack .../libnss3-nssdb_2%3a3.28.4-0ubuntu0.16.04.13_all.deb ...\n",
      "Unpacking libnss3-nssdb (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../libnss3_2%3a3.28.4-0ubuntu0.16.04.13_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../libpcsclite1_1.8.14-1ubuntu1.16.04.1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.14-1ubuntu1.16.04.1) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../openjdk-8-jre-headless_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jre-headless.\n",
      "Preparing to unpack .../default-jre-headless_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.8-56ubuntu2) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../ca-certificates-java_20160321ubuntu1_all.deb ...\n",
      "Unpacking ca-certificates-java (20160321ubuntu1) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../libasound2-data_1.1.0-0ubuntu1_all.deb ...\n",
      "Unpacking libasound2-data (1.1.0-0ubuntu1) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../libasound2_1.1.0-0ubuntu1_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.0-0ubuntu1) ...\n",
      "Selecting previously unselected package libgif7:amd64.\n",
      "Preparing to unpack .../libgif7_5.1.4-0.3~16.04.1_amd64.deb ...\n",
      "Unpacking libgif7:amd64 (5.1.4-0.3~16.04.1) ...\n",
      "Selecting previously unselected package libflac8:amd64.\n",
      "Preparing to unpack .../libflac8_1.3.1-4_amd64.deb ...\n",
      "Unpacking libflac8:amd64 (1.3.1-4) ...\n",
      "Selecting previously unselected package libsndfile1:amd64.\n",
      "Preparing to unpack .../libsndfile1_1.0.25-10ubuntu0.16.04.2_amd64.deb ...\n",
      "Unpacking libsndfile1:amd64 (1.0.25-10ubuntu0.16.04.2) ...\n",
      "Selecting previously unselected package libpulse0:amd64.\n",
      "Preparing to unpack .../libpulse0_1%3a8.0-0ubuntu3.12_amd64.deb ...\n",
      "Unpacking libpulse0:amd64 (1:8.0-0ubuntu3.12) ...\n",
      "Selecting previously unselected package openjdk-8-jre:amd64.\n",
      "Preparing to unpack .../openjdk-8-jre_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../default-jre_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jre (2:1.8-56ubuntu2) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../openjdk-8-jdk-headless_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jdk-headless.\n",
      "Preparing to unpack .../default-jdk-headless_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jdk-headless (2:1.8-56ubuntu2) ...\n",
      "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
      "Preparing to unpack .../openjdk-8-jdk_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jdk.\n",
      "Preparing to unpack .../default-jdk_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jdk (2:1.8-56ubuntu2) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11.2) ...\n",
      "Processing triggers for ca-certificates (20190110~16.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "Processing triggers for mime-support (3.59ubuntu1) ...\n",
      "Setting up libasyncns0:amd64 (0.8-5build1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.2-1) ...\n",
      "Setting up java-common (0.56ubuntu2) ...\n",
      "Setting up liblcms2-2:amd64 (2.6-3ubuntu2.1) ...\n",
      "Setting up libnspr4:amd64 (2:4.13.1-0ubuntu0.16.04.1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.14-1ubuntu1.16.04.1) ...\n",
      "Setting up libasound2-data (1.1.0-0ubuntu1) ...\n",
      "Setting up libasound2:amd64 (1.1.0-0ubuntu1) ...\n",
      "Setting up libgif7:amd64 (5.1.4-0.3~16.04.1) ...\n",
      "Setting up libflac8:amd64 (1.3.1-4) ...\n",
      "Setting up libsndfile1:amd64 (1.0.25-10ubuntu0.16.04.2) ...\n",
      "Setting up libpulse0:amd64 (1:8.0-0ubuntu3.12) ...\n",
      "Setting up libnss3-nssdb (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Setting up libnss3:amd64 (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up default-jre-headless (2:1.8-56ubuntu2) ...\n",
      "Setting up openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
      "Setting up default-jre (2:1.8-56ubuntu2) ...\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "Setting up default-jdk-headless (2:1.8-56ubuntu2) ...\n",
      "Setting up openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Setting up default-jdk (2:1.8-56ubuntu2) ...\n",
      "Setting up ca-certificates-java (20160321ubuntu1) ...\n",
      "Adding debian:thawte_Primary_Root_CA.pem\n",
      "Adding debian:Certplus_Class_2_Primary_CA.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G5.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G4.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority.pem\n",
      "Adding debian:DST_Root_CA_X3.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:VeriSign_Universal_Root_Certification_Authority.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:GeoTrust_Global_CA.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:Deutsche_Telekom_Root_CA_2.pem\n",
      "Adding debian:thawte_Primary_Root_CA_-_G2.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:GeoTrust_Universal_CA.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Taiwan_GRCA.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:thawte_Primary_Root_CA_-_G3.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G2.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GA_CA.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:LuxTrust_Global_Root_2.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Certinomis_-_Root_CA.pem\n",
      "Adding debian:Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:EE_Certification_Centre_Root_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:GeoTrust_Universal_CA_2.pem\n",
      "done.\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11.2) ...\n",
      "Processing triggers for ca-certificates (20190110~16.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Removing intermediate container 076974884a35\n",
      " ---> 26fc46725d87\n",
      "Step 9/13 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 2410d3aa22a0\n",
      "Removing intermediate container 2410d3aa22a0\n",
      " ---> 18e1c6168f09\n",
      "Step 10/13 : COPY code/custom_lightgbm_inference-0.1.0.tar.gz /custom_lightgbm_inference-0.1.0.tar.gz\n",
      " ---> 4025123f2213\n",
      "Step 11/13 : RUN ${PIP} install --no-cache --upgrade         /custom_lightgbm_inference-0.1.0.tar.gz &&     rm /custom_lightgbm_inference-0.1.0.tar.gz\n",
      " ---> Running in dd3a733743ce\n",
      "Processing /custom_lightgbm_inference-0.1.0.tar.gz\n",
      "Collecting sagemaker-inference==1.3.0\n",
      "  Downloading sagemaker_inference-1.3.0.tar.gz (17 kB)\n",
      "Collecting multi-model-server==1.1.2\n",
      "  Downloading multi_model_server-1.1.2-py2.py3-none-any.whl (4.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (5.7.2)\n",
      "Requirement already satisfied, skipping upgrade: retrying==1.3.3 in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.3.3)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting model-archiver\n",
      "  Downloading model_archiver-1.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Using legacy setup.py install for custom-lightgbm-inference, since package 'wheel' is not installed.\n",
      "Using legacy setup.py install for sagemaker-inference, since package 'wheel' is not installed.\n",
      "Using legacy setup.py install for future, since package 'wheel' is not installed.\n",
      "Installing collected packages: sagemaker-inference, Pillow, future, enum-compat, model-archiver, multi-model-server, custom-lightgbm-inference\n",
      "    Running setup.py install for sagemaker-inference: started\n",
      "    Running setup.py install for sagemaker-inference: finished with status 'done'\n",
      "    Running setup.py install for future: started\n",
      "    Running setup.py install for future: finished with status 'done'\n",
      "    Running setup.py install for custom-lightgbm-inference: started\n",
      "    Running setup.py install for custom-lightgbm-inference: finished with status 'done'\n",
      "Successfully installed Pillow-7.2.0 custom-lightgbm-inference-0.1.0 enum-compat-0.0.3 future-0.18.2 model-archiver-1.0.3 multi-model-server-1.1.2 sagemaker-inference-1.3.0\n",
      "\u001b[91mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container dd3a733743ce\n",
      " ---> 2bcf6c358eba\n",
      "Step 12/13 : ENV SM_MODEL_DIR /opt/ml/model\n",
      " ---> Running in a557254dcb4c\n",
      "Removing intermediate container a557254dcb4c\n",
      " ---> 2fb2c6160e52\n",
      "Step 13/13 : ENV CODE_DIR /opt/ml/code\n",
      " ---> Running in ec7cbc182647\n",
      "Removing intermediate container ec7cbc182647\n",
      " ---> 49cb0e6f8d80\n",
      "Successfully built 49cb0e6f8d80\n",
      "Successfully tagged iris_model:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker build -f docker/Dockerfile -t iris_model:1.0 ./docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Now that we have the algorithm image we can run it to train/deploy a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we need to prepare the dataset\n",
    "You'll see that we're splitting the dataset into training and validation and also saving these two subsets of the dataset into csv files. These files will be then uploaded to an S3 Bucket and shared with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_id</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_id  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0      0.0                5.1               3.5                1.4   \n",
       "1      0.0                4.9               3.0                1.4   \n",
       "2      0.0                4.7               3.2                1.3   \n",
       "3      0.0                4.6               3.1                1.5   \n",
       "4      0.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf input\n",
    "!mkdir -p input/data/training\n",
    "!mkdir -p input/data/testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=dataset, columns=[\"iris_id\"] + iris.feature_names)\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df.insert(0, \"iris_id\", y_train)\n",
    "train_df.to_csv(\"input/data/training/training.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df.insert(0, \"iris_id\", y_test)\n",
    "test_df.to_csv(\"input/data/testing/testing.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Just a basic local test, using the local Docker daemon\n",
    "Here we will simulate SageMaker calling our docker container for training and serving. We'll do that using the built-in Docker Daemon of the Jupyter Notebook Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input/config && mkdir -p input/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/hyperparameters.json\n",
    "{\"max_depth\": 20, \"n_jobs\": 4, \"n_estimators\": 120}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/resourceconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/resourceconfig.json\n",
    "{\"current_host\": \"localhost\", \"hosts\": [\"algo-1-kipw9\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/inputdataconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/inputdataconfig.json\n",
    "{\"training\": {\"TrainingInputMode\": \"File\"}, \"testing\": {\"TrainingInputMode\": \"File\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "2020-07-28 15:53:41,354 sagemaker-training-toolkit INFO     Imported framework my_training\n",
      "CPU times: user 39.6 ms, sys: 13.9 ms, total: 53.5 ms\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!rm -rf model/\n",
    "!mkdir -p model\n",
    "\n",
    "print( \"Training...\")\n",
    "!docker run --rm --name \"my_model\" \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 This is the serving test. It simulates an Endpoint exposed by Sagemaker\n",
    "\n",
    "After you execute the next cell, this Jupyter notebook will freeze. A webservice will be exposed at the port 8080. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/serve\", line 5, in <module>\n",
      "    from custom_inference.cli.init_serve import main\n",
      "ModuleNotFoundError: No module named 'custom_inference'\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --name \"my_model\" \\\n",
    "    -p 8080:8080 \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the above cell is running, click here [TEST NOTEBOOK](02_Testing%20our%20local%20model%20server.ipynb) to run some tests.\n",
    "\n",
    "> After you finish the tests, press **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 - Integrated Test: Everything seems ok, now it's time to put all together\n",
    "\n",
    "We'll start by running a local **CodeBuild** test, to check the buildspec and also deploy this image into the container registry. Remember that SageMaker will only see images published to ECR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name=\"iris-model\"\n",
    "image_tag=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf tests && mkdir -p tests\n",
    "# !cp handler.py main.py train.py Dockerfile buildspec.yml tests/\n",
    "!cp handler_service.py inference_handler.py serving.py training.py Dockerfile buildspec.yml tests/\n",
    "with open(\"tests/vars.env\", \"w\") as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Command:\n",
      "\n",
      "docker run -it -v /var/run/docker.sock:/var/run/docker.sock -e \"IMAGE_NAME=samirsouza/aws-codebuild-standard:3.0\" -e \"ARTIFACTS=/home/ec2-user/SageMaker/tmp_ars/amazon-sagemaker-mlops-workshop/lab/01_CreateAlgorithmContainer/scikit_based/tests/output\" -e \"SOURCE=/home/ec2-user/SageMaker/tmp_ars/amazon-sagemaker-mlops-workshop/lab/01_CreateAlgorithmContainer/scikit_based/tests\" -v \"/home/ec2-user/SageMaker/tmp_ars/amazon-sagemaker-mlops-workshop/lab/01_CreateAlgorithmContainer/scikit_based/tests:/LocalBuild/envFile/\" -e \"ENV_VAR_FILE=vars.env\" -e \"AWS_CONFIGURATION=/home/ec2-user/.aws\" -e \"AWS_CLOUDWATCH_HOME=/opt/aws/apitools/mon\" -e \"AWS_PATH=/opt/aws\" -e \"AWS_AUTO_SCALING_HOME=/opt/aws/apitools/as\" -e \"AWS_ELB_HOME=/opt/aws/apitools/elb\" -e \"INITIATOR=ec2-user\" amazon/aws-codebuild-local:latest\n",
      "\n",
      "Removing agent-resources_build_1 ... \n",
      "Removing agent-resources_agent_1 ... \n",
      "\u001b[2BRemoving network agent-resources_defaultne\u001b[0m\n",
      "Removing volume agent-resources_source_volume\n",
      "Removing volume agent-resources_user_volume\n",
      "Creating network \"agent-resources_default\" with the default driver\n",
      "Creating volume \"agent-resources_source_volume\" with local driver\n",
      "Creating volume \"agent-resources_user_volume\" with local driver\n",
      "Creating agent-resources_agent_1 ... \n",
      "\u001b[1BCreating agent-resources_build_1 ... mdone\u001b[0m\n",
      "\u001b[1BAttaching to agent-resources_agent_1, agent-resources_build_1\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:42 Waiting for agent ping\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:43 Waiting for DOWNLOAD_SOURCE\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase is DOWNLOAD_SOURCE\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 CODEBUILD_SRC_DIR=/codebuild/output/src145685821/src\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 YAML location is /codebuild/output/srcDownload/src/buildspec.yml\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 No commands found for phase name: install\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Processing environment variables\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Running command echo \"Specifying docker version in buildspec is deprecated. Using docker $DOCKER_VERSION .\"\n",
      "\u001b[36magent_1  |\u001b[0m Specifying docker version in buildspec is deprecated. Using docker 19.03.1 .\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Moving to directory /codebuild/output/src145685821/src\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Registering with agent\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phases found in YAML: 4\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  INSTALL: 0 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  PRE_BUILD: 2 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  BUILD: 4 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  POST_BUILD: 6 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Entering phase INSTALL\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase complete: INSTALL State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Entering phase PRE_BUILD\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Running command echo Logging in to Amazon ECR...\n",
      "\u001b[36magent_1  |\u001b[0m Logging in to Amazon ECR...\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "\u001b[36magent_1  |\u001b[0m WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\u001b[36magent_1  |\u001b[0m WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "\u001b[36magent_1  |\u001b[0m Configure a credential helper to remove this warning. See\n",
      "\u001b[36magent_1  |\u001b[0m https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m Login Succeeded\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Entering phase BUILD\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Build started on `date`\n",
      "\u001b[36magent_1  |\u001b[0m Build started on Sun Jul 19 01:11:45 UTC 2020\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Building the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m Building the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
      "\u001b[36magent_1  |\u001b[0m Sending build context to Docker daemon  14.85kB\n",
      "\u001b[36magent_1  |\u001b[0m Step 1/22 : FROM python:3.7-buster\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 014d597185ae\n",
      "\u001b[36magent_1  |\u001b[0m Step 2/22 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> c82281ba180f\n",
      "\u001b[36magent_1  |\u001b[0m Step 3/22 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 18c25a86e34c\n",
      "\u001b[36magent_1  |\u001b[0m Step 4/22 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 9573566cf408\n",
      "\u001b[36magent_1  |\u001b[0m Step 5/22 : RUN rm -rf /var/lib/apt/lists/*\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> be6f32780091\n",
      "\u001b[36magent_1  |\u001b[0m Step 6/22 : RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 9026024a47b9\n",
      "\u001b[36magent_1  |\u001b[0m Step 7/22 : RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 4a8b1f8822ea\n",
      "\u001b[36magent_1  |\u001b[0m Step 8/22 : ENV PYTHONUNBUFFERED=TRUE\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> edf93ea7a7b9\n",
      "\u001b[36magent_1  |\u001b[0m Step 9/22 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 1dedecf679e4\n",
      "\u001b[36magent_1  |\u001b[0m Step 10/22 : ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> ed6a6a821886\n",
      "\u001b[36magent_1  |\u001b[0m Step 11/22 : ENV SM_INPUT /opt/ml/input\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 744511fe7ee1\n",
      "\u001b[36magent_1  |\u001b[0m Step 12/22 : ENV SM_INPUT_TRAINING_CONFIG_FILE $SM_INPUT/config/hyperparameters.json\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 377b7650dfa8\n",
      "\u001b[36magent_1  |\u001b[0m Step 13/22 : ENV SM_INPUT_DATA_CONFIG_FILE $SM_INPUT/config/inputdataconfig.json\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 02d2919f0283\n",
      "\u001b[36magent_1  |\u001b[0m Step 14/22 : ENV SM_CHECKPOINT_CONFIG_FILE $SM_INPUT/config/checkpointconfig.json\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> b3b74c163fb8\n",
      "\u001b[36magent_1  |\u001b[0m Step 15/22 : ENV SM_MODEL_DIR /opt/ml/model\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 2faa8bc3f758\n",
      "\u001b[36magent_1  |\u001b[0m Step 16/22 : ENV CODE_DIR /opt/ml/code\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 881103ee9f05\n",
      "\u001b[36magent_1  |\u001b[0m Step 17/22 : COPY training.py $CODE_DIR/training.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 700944b70c00\n",
      "\u001b[36magent_1  |\u001b[0m Step 18/22 : COPY handler_service.py $CODE_DIR/handler_service.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> efa3260a5064\n",
      "\u001b[36magent_1  |\u001b[0m Step 19/22 : COPY inference_handler.py $CODE_DIR/inference_handler.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> ddb703a11bab\n",
      "\u001b[36magent_1  |\u001b[0m Step 20/22 : COPY serving.py $CODE_DIR/serving.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 172c8feb8f49\n",
      "\u001b[36magent_1  |\u001b[0m Step 21/22 : ENV SAGEMAKER_TRAINING_MODULE training:main\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 1f78c4063698\n",
      "\u001b[36magent_1  |\u001b[0m Step 22/22 : ENV SAGEMAKER_SERVING_MODULE serving:main\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 0d9dabd3deb3\n",
      "\u001b[36magent_1  |\u001b[0m Successfully built 0d9dabd3deb3\n",
      "\u001b[36magent_1  |\u001b[0m Successfully tagged iris-model:test\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase complete: BUILD State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Entering phase POST_BUILD\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Build completed on `date`\n",
      "\u001b[36magent_1  |\u001b[0m Build completed on Sun Jul 19 01:11:45 UTC 2020\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Pushing the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m Pushing the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\u001b[36magent_1  |\u001b[0m docker push 725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model:test\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\u001b[36magent_1  |\u001b[0m The push refers to repository [725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model]\n",
      "\u001b[36magent_1  |\u001b[0m 128bcde6208b: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 2d733ae4b0e4: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 46fde1d9c157: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m bd48c3aeea6d: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 854ec304b9e1: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m f2b8baa9bbe1: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m bd070b0e24c9: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 34c4b72d562c: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m f1535a5a6c0c: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 3e01f9fd787f: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 646632873240: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 98d95bdfa037: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m da9418a2e1b1: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 2e5b4ca91984: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 527ade4639e0: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m c2c789d2d3c5: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 8803ef42039d: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m f1535a5a6c0c: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 3e01f9fd787f: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 646632873240: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 98d95bdfa037: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m bd070b0e24c9: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m da9418a2e1b1: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 2e5b4ca91984: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 34c4b72d562c: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 527ade4639e0: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m f2b8baa9bbe1: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m c2c789d2d3c5: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 8803ef42039d: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 2d733ae4b0e4: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 128bcde6208b: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m bd48c3aeea6d: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 46fde1d9c157: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m bd070b0e24c9: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 3e01f9fd787f: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m f1535a5a6c0c: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 98d95bdfa037: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 854ec304b9e1: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 646632873240: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 527ade4639e0: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m c2c789d2d3c5: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m f2b8baa9bbe1: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 2e5b4ca91984: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 8803ef42039d: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 34c4b72d562c: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m da9418a2e1b1: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m test: digest: sha256:fa13804f99ef839f111cfe03441b489e25eef563fcfbc780da9420a9ad44f770 size: 3891\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Running command echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Running command echo Done\n",
      "\u001b[36magent_1  |\u001b[0m Done\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding base directory path: .\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Assembling file list\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding .\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding file paths for base directory .\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Assembling file list\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding image.url\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Found 1 file(s)\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Preparing to copy secondary artifacts\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 No secondary artifacts defined in buildspec\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase complete: UPLOAD_ARTIFACTS State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase context status code:  Message: \n",
      "\u001b[33magent-resources_build_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "CPU times: user 962 ms, sys: 167 ms, total: 1.13 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:3.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\" \\\n",
    "    -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have an image deployed in the ECR repo we can also run some local tests using the SageMaker Estimator.\n",
    "\n",
    "> Click on this [TEST NOTEBOOK](03_Testing%20the%20container%20using%20SageMaker%20Estimator.ipynb) to run some tests.\n",
    "\n",
    "> After you finishing the tests, come back to **this notebook** to push the assets to the Git Repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4 - Let's push all the assets to the Git Repo connected to the Build pipeline\n",
    "There is a CodePipeine configured to keep listeining to this Git Repo and start a new Building process with CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../../../mlops\n",
    "git checkout iris_model\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - files for building an iris model image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Alright, now open the AWS console and go to the **CodePipeline** dashboard. Look for a pipeline called **mlops-iris-model**. This pipeline will deploy the final image to an ECR repo. When this process finishes, open the **Elastic Compute Registry** dashboard, in the AWS console, and check if you have an image called **iris-model:latest**. If yes, you can go to the next exercise. If not, wait a little more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
